epochs = 20
batch_size = 20
max textlength = 50
preprocess-typ = stopwords
attention model = simple
best model with max val_acc
2 LSTM Layer
Dropout & Noise = 0.3

model accuracy (loss value, accuracy):
[0.5070901272465925, 0.7938144330048631]

confusion matrix:
[[2173  668  159]
 [ 123 1654   80]
 [ 205  385 2410]]

classification report:
             precision    recall  f1-score   support

          0       0.87      0.72      0.79      3000
          1       0.61      0.89      0.72      1857
          2       0.91      0.80      0.85      3000

avg / total       0.82      0.79      0.80      7857


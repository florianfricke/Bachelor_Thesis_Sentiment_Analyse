epochs = 20
batch_size = 20
max textlength = 50
preprocess-typ = stopwords
attention model = simple
best model with min val_loss
dropout_attention = 0.5

model accuracy (loss value, accuracy):
[0.741123948536064, 0.635673624476928]

confusion matrix:
[[293  64  45]
 [307 541  81]
 [ 46  33 171]]

classification report:
             precision    recall  f1-score   support

          0       0.45      0.73      0.56       402
          1       0.85      0.58      0.69       929
          2       0.58      0.68      0.63       250

avg / total       0.70      0.64      0.65      1581


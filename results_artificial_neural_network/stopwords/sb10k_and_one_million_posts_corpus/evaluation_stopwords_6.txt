epochs = 60
batch_size = 20
max textlength = 50
preprocess-typ = stopwords
attention model = simple
best model with max val_acc
dropout_attention = 0.1
2 LSTM Layer
Dropout & Noise = 0.1

model accuracy (loss value, accuracy):
[1.2853222301171499, 0.67700094899132601]

confusion matrix:
[[ 457  289   57]
 [ 338 1390  129]
 [  54  154  293]]

classification report:
             precision    recall  f1-score   support

          0       0.54      0.57      0.55       803
          1       0.76      0.75      0.75      1857
          2       0.61      0.58      0.60       501

avg / total       0.68      0.68      0.68      3161


epochs = 10
batch_size = 20
max textlength = 50
preprocess-typ = stopwords2
attention model = simple
best model with max val_acc
dropout_attention = 0.1
2 LSTM Layer
Dropout & Noise = 0.1

model accuracy (loss value, accuracy):
[0.7664345317119211, 0.6165770328109003]

confusion matrix:
[[635  85  83]
 [682 957 218]
 [ 80  64 357]]

classification report:
             precision    recall  f1-score   support

          0       0.45      0.79      0.58       803
          1       0.87      0.52      0.65      1857
          2       0.54      0.71      0.62       501

avg / total       0.71      0.62      0.62      3161


epochs = 20
batch_size = 20
max textlength = 50
preprocess-typ = ekphrasis
attention model = simple
best model with max val_acc
dropout_attention = 0.1
2 LSTM Layer
Dropout & Noise = 0.1

model accuracy (loss value, accuracy):
[0.7677179125244578, 0.677633660290672]

confusion matrix:
[[ 482  237   84]
 [ 382 1310  165]
 [  49  102  350]]

classification report:
             precision    recall  f1-score   support

          0       0.53      0.60      0.56       803
          1       0.79      0.71      0.75      1857
          2       0.58      0.70      0.64       501

avg / total       0.69      0.68      0.68      3161


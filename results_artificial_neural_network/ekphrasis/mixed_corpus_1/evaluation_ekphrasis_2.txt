epochs = 20
batch_size = 20
max textlength = 50
preprocess-typ = ekphrasis
attention model = simple
best model with max val_acc
2 LSTM Layer
Dropout & Noise = 0.3

model accuracy (loss value, accuracy):
[0.5255479647281198, 0.7762504772965775]

confusion matrix:
[[2068  814  118]
 [  74 1747   36]
 [ 254  462 2284]]

classification report:
             precision    recall  f1-score   support

          0       0.86      0.69      0.77      3000
          1       0.58      0.94      0.72      1857
          2       0.94      0.76      0.84      3000

avg / total       0.82      0.78      0.78      7857


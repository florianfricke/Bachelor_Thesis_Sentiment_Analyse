epochs = 50
batch_size = 10
max textlength = 50
preprocess-typ = emphrasis
attention model = simple
best model with min val_loss
dropout_attention = 0.5
3 LSTM Layer

model accuracy (loss value, accuracy):
[0.781462306956714, 0.6331435802011532]

confusion matrix:
[[267  85  50]
 [262 536 131]
 [ 26  26 198]]

classification report:
             precision    recall  f1-score   support

          0       0.48      0.66      0.56       402
          1       0.83      0.58      0.68       929
          2       0.52      0.79      0.63       250

avg / total       0.69      0.63      0.64      1581

